{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports & Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:52:12.158293Z",
     "iopub.status.busy": "2024-05-21T10:52:12.157242Z",
     "iopub.status.idle": "2024-05-21T10:52:12.170569Z",
     "shell.execute_reply": "2024-05-21T10:52:12.169731Z",
     "shell.execute_reply.started": "2024-05-21T10:52:12.158256Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:53:12.498301Z",
     "iopub.status.busy": "2024-05-21T10:53:12.497126Z",
     "iopub.status.idle": "2024-05-21T10:53:20.758230Z",
     "shell.execute_reply": "2024-05-21T10:53:20.757210Z",
     "shell.execute_reply.started": "2024-05-21T10:53:12.498268Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting utils\n",
      "  Downloading utils-1.0.2.tar.gz (13 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: utils\n",
      "  Building wheel for utils (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for utils: filename=utils-1.0.2-py2.py3-none-any.whl size=13904 sha256=a84350823bc7aa0c9512af7fa6fa203585c07bb16ba2bc35fccfc8b0b0d127ca\n",
      "  Stored in directory: /tmp/xdg_cache/pip/wheels/b8/39/f5/9d0ca31dba85773ececf0a7f5469f18810e1c8a8ed9da28ca7\n",
      "Successfully built utils\n",
      "Installing collected packages: utils\n",
      "Successfully installed utils-1.0.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../../utils\")\n",
    "from definitions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:59:10.231986Z",
     "iopub.status.busy": "2024-05-21T10:59:10.231089Z",
     "iopub.status.idle": "2024-05-21T10:59:18.102843Z",
     "shell.execute_reply": "2024-05-21T10:59:18.101858Z",
     "shell.execute_reply.started": "2024-05-21T10:59:10.231947Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /tmp/xdg_cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\",\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\",\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\",\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    message=\"`do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\",\n",
    ")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../utils\")\n",
    "from definitions import *\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../../LongLoRA-diploma-research\")\n",
    "\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "login(os.environ['hf-read-token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:59:18.106044Z",
     "iopub.status.busy": "2024-05-21T10:59:18.105253Z",
     "iopub.status.idle": "2024-05-21T10:59:18.148748Z",
     "shell.execute_reply": "2024-05-21T10:59:18.148053Z",
     "shell.execute_reply.started": "2024-05-21T10:59:18.106010Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MODEL_EXPERIMENT_NAME = \"lora_v1_correct_run\"\n",
    "MODEL_MAX_LENGTH = 16384\n",
    "INPUT_COLUMNS = [\"test_row\", \"id\", \"diploma\"] # ['id', 'abstract', 'diploma', 'begin', 'raw_model_v2', 'learnt']\n",
    "CACHE_DIR = Path(\"../../../../cache/\")\n",
    "DATASET_DIR = Path(\"/home/jupyter/mnt/datasets/diplomas/russian_dataset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load inputs & assessors dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:59:18.150451Z",
     "iopub.status.busy": "2024-05-21T10:59:18.149732Z",
     "iopub.status.idle": "2024-05-21T10:59:18.352214Z",
     "shell.execute_reply": "2024-05-21T10:59:18.351409Z",
     "shell.execute_reply.started": "2024-05-21T10:59:18.150427Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diploma</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_row</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>45042</td>\n",
       "      <td>АЙВАЗЬЯН Аршак Владимирович\\nВыпускная квалифи...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>45043</td>\n",
       "      <td>Санкт-Петербургский государственный университе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>45044</td>\n",
       "      <td>Санкт-Петербургский государственный университе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>45046</td>\n",
       "      <td>Санкт-Петербургский государственный университе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>45047</td>\n",
       "      <td>Санкт–Петербургский государственный университе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1062</th>\n",
       "      <td>45131</td>\n",
       "      <td>Санкт-Петербургский государственный университе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1064</th>\n",
       "      <td>45132</td>\n",
       "      <td>Санкт-Петербургский государственный университе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>45133</td>\n",
       "      <td>Санкт-Петербургский государственный университе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209</th>\n",
       "      <td>45135</td>\n",
       "      <td>Санкт–Петербургский государственный университе...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>45137</td>\n",
       "      <td>Санкт–Петербургский государственный университе...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                            diploma\n",
       "test_row                                                          \n",
       "12        45042  АЙВАЗЬЯН Аршак Владимирович\\nВыпускная квалифи...\n",
       "25        45043  Санкт-Петербургский государственный университе...\n",
       "37        45044  Санкт-Петербургский государственный университе...\n",
       "101       45046  Санкт-Петербургский государственный университе...\n",
       "152       45047  Санкт–Петербургский государственный университе...\n",
       "...         ...                                                ...\n",
       "1062      45131  Санкт-Петербургский государственный университе...\n",
       "1064      45132  Санкт-Петербургский государственный университе...\n",
       "1079      45133  Санкт-Петербургский государственный университе...\n",
       "1209      45135  Санкт–Петербургский государственный университе...\n",
       "1238      45137  Санкт–Петербургский государственный университе...\n",
       "\n",
       "[70 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = pd.read_csv(ARTIFACTS_DIR_PATH.joinpath(\"metrics/diplomas_asessors_questions/inputs.csv\"), usecols=INPUT_COLUMNS)\n",
    "inputs = inputs.set_index(\"test_row\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:59:18.354716Z",
     "iopub.status.busy": "2024-05-21T10:59:18.353728Z",
     "iopub.status.idle": "2024-05-21T10:59:18.405214Z",
     "shell.execute_reply": "2024-05-21T10:59:18.404445Z",
     "shell.execute_reply.started": "2024-05-21T10:59:18.354686Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'На что направлена ВКР на тему \"Геометрическая интерпретация множеств мономов, допускающих поверхность с особенностью данного порядка\"?',\n",
       "   'option_a': 'На приложение геометрических условий к архитектуре нейросетей в машинном обучении',\n",
       "   'option_b': 'На исследование матроида с помощью пакета SageMath',\n",
       "   'option_c': 'На то, чтобы сделать обзор литературы в области геометрических интерпретаций',\n",
       "   'option_d': 'На выяснение геометрических условий, при которых заданное конечное множество мономов от трех переменных допускает задание поверхности с особенностью данного порядка уравнением вида \"линейная комбинация мономов этого множества равна нулю\"',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'ВКР на тему \"Геометрическая интерпретация множеств мономов, допускающих поверхность с особенностью данного порядка\" направлена на выяснение геометрических условий, при которых заданное конечное множество мономов от трех переменных допускает задание поверхности с особенностью данного порядка уравнением вида \"линейная комбинация мономов этого множества равна нулю\". \\n\\nСтруктура данной работы выглядит следующим образом. Первый раздел (\"Введение\") содержит постановку задачи и ее переформулировку в терминах ранга соответствующей матрицы. Второй раздел (\"Геометрическая интерпретация множества A\") содержит описание геометрических подходов к исследуемой задаче. Третий раздел (\"Матроид недопускающих множеств\") содержит описание матроидного подхода к проблеме, в том числе необходимые сведения из теории матроидов и интерпретацию этих сведений в контексте работы. В последнем разделе \"Исследование матроида с помощью пакета SageMath\" приводится несколько классификационных теорем о матроиде из предыдущего раздела, доказанных с помощью компьютерного перебора и системы компьютерной алгебры SageMath. В конце ВКР приведен список литературы.'},\n",
       "  'outputs': 'D',\n",
       "  'meta': {'abstract': 'ВКР на тему \"Геометрическая интерпретация множеств мономов, допускающих поверхность с особенностью данного порядка\" направлена на выяснение геометрических условий, при которых заданное конечное множество мономов от трех переменных допускает задание поверхности с особенностью данного порядка уравнением вида \"линейная комбинация мономов этого множества равна нулю\". \\n\\nСтруктура данной работы выглядит следующим образом. Первый раздел (\"Введение\") содержит постановку задачи и ее переформулировку в терминах ранга соответствующей матрицы. Второй раздел (\"Геометрическая интерпретация множества A\") содержит описание геометрических подходов к исследуемой задаче. Третий раздел (\"Матроид недопускающих множеств\") содержит описание матроидного подхода к проблеме, в том числе необходимые сведения из теории матроидов и интерпретацию этих сведений в контексте работы. В последнем разделе \"Исследование матроида с помощью пакета SageMath\" приводится несколько классификационных теорем о матроиде из предыдущего раздела, доказанных с помощью компьютерного перебора и системы компьютерной алгебры SageMath. В конце ВКР приведен список литературы.',\n",
       "   'id': '702'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Что предоставляет готовое мобильное приложение, являющееся результатом работы, в настольной ролевой игре Подземелья и Драконы (Dungeons & Dragons, D&D)?',\n",
       "   'option_a': 'Удобные инструменты для создания и управления персонажами',\n",
       "   'option_b': 'Возможность запускать нейросети для генерации изображений',\n",
       "   'option_c': 'Графический интерфейс для игры в D&D по сети',\n",
       "   'option_d': 'Возможность обучать модели через обучение с подкреплением',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Результатом работы является готовое мобильное приложение, предоставляющее удобные инструменты для создания и управления персонажами в настольной ролевой игре Подземелья и Драконы (Dungeons & Dragons, D&D). Приложение использует передовые технологии, такие как нейросети, для генерации текста и изображений. Генерация текста позволяет игрокам получать увлекательные предыстории своих персонажей, а генерация изображений создает визуальное представление персонажей без необходимости рисования или поиска картинок в интернете. Приложение также обладает удобной навигацией, продуманными элементами интерфейса и поддержкой русского языка.'},\n",
       "  'outputs': 'A',\n",
       "  'meta': {'abstract': 'Результатом работы является готовое мобильное приложение, предоставляющее удобные инструменты для создания и управления персонажами в настольной ролевой игре Подземелья и Драконы (Dungeons & Dragons, D&D). Приложение использует передовые технологии, такие как нейросети, для генерации текста и изображений. Генерация текста позволяет игрокам получать увлекательные предыстории своих персонажей, а генерация изображений создает визуальное представление персонажей без необходимости рисования или поиска картинок в интернете. Приложение также обладает удобной навигацией, продуманными элементами интерфейса и поддержкой русского языка.',\n",
       "   'id': '708'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Главная цель этой работы была создать новые алгоритмы для решения какой задачи?',\n",
       "   'option_a': 'Задачи поиска интервалов разладки',\n",
       "   'option_b': 'Задачи поиска обратного преобразования',\n",
       "   'option_c': 'Задачи тысячелетия',\n",
       "   'option_d': 'Задачи нахождения голоморфной функции по заданному параметру',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Для крупных современных информационных систем очень важно следить за производительностью. Вручную отслеживать изменения в таких системах практически невозможно из-за их размера. Поэтому автоматизация этой части процесса мониторинга имеет решающее значение. Задача мониторинга  может быть сведена к задачи поиска интервалов разладки во временных сериях времен работы системы. Главная цель этой работы была создать новые алгоритмы для решения задачи поиска интервалов разладки. В работе презентуется несколько отличающихся подходов к решению задачи. Эффективность всех построенных алгоритмов проверена как на синтетических, так и на реальных наборах данных.'},\n",
       "  'outputs': 'A',\n",
       "  'meta': {'abstract': 'Для крупных современных информационных систем очень важно следить за производительностью. Вручную отслеживать изменения в таких системах практически невозможно из-за их размера. Поэтому автоматизация этой части процесса мониторинга имеет решающее значение. Задача мониторинга  может быть сведена к задачи поиска интервалов разладки во временных сериях времен работы системы. Главная цель этой работы была создать новые алгоритмы для решения задачи поиска интервалов разладки. В работе презентуется несколько отличающихся подходов к решению задачи. Эффективность всех построенных алгоритмов проверена как на синтетических, так и на реальных наборах данных.',\n",
       "   'id': '727'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В работе редставляется разработка анализатора, генерирующего модульные тесты в виде чего?',\n",
       "   'option_a': 'В виде фаззинг тестов',\n",
       "   'option_b': 'В виде эксплойтов для кода',\n",
       "   'option_c': 'В виде юнит тестов',\n",
       "   'option_d': 'В виде встраимываемых кусков ассемблерного кода',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Данная работа посвящена динамическому анализу кода, а именно поиску уязвимостей с использованием символьного исполнения. Представляется разработка анализатора, генерирующего модульные тесты в виде эксплойтов для кода. В работе присутствует анализ других инструментов, описание реализации и примеры использования.'},\n",
       "  'outputs': 'B',\n",
       "  'meta': {'abstract': 'Данная работа посвящена динамическому анализу кода, а именно поиску уязвимостей с использованием символьного исполнения. Представляется разработка анализатора, генерирующего модульные тесты в виде эксплойтов для кода. В работе присутствует анализ других инструментов, описание реализации и примеры использования.',\n",
       "   'id': '752'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Эта работа посвящена проектированию и разработке чего?',\n",
       "   'option_a': 'Компилятора для универсальной символьной машины',\n",
       "   'option_b': 'Универсальной символьной виртуальной машины',\n",
       "   'option_c': 'Конкретной символьной виртуальной машины',\n",
       "   'option_d': 'Современных подходов в символьном исполнении',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Эта работа посвящена проектированию и разработке универсальной символьной виртуальной машины. В работе описываются современные подходы в символьном исполнении, приводится архитектура и технические подробности реализованного решения, а также проводятся сравнения с аналогичными продуктами и замеры скорости работы.'},\n",
       "  'outputs': 'B',\n",
       "  'meta': {'abstract': 'Эта работа посвящена проектированию и разработке универсальной символьной виртуальной машины. В работе описываются современные подходы в символьном исполнении, приводится архитектура и технические подробности реализованного решения, а также проводятся сравнения с аналогичными продуктами и замеры скорости работы.',\n",
       "   'id': '773'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Во сколько раз превосходит по производительности современные методы выделения сочинительных связей результат, полученный в работе и который сопоставим по качеству с ними?',\n",
       "   'option_a': '52',\n",
       "   'option_b': '2',\n",
       "   'option_c': 'Полученный результат уступает по производительности',\n",
       "   'option_d': '3',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Данная работа посвящена решению задачи выделения сочинительных связей в предложениях на английском языке нейросетевыми методами. Решение этой задачи позволяет устанавливать потенциально ценные связи и отношения между определёнными частями предложения; в том числе поэтому выделение сочинительных связей — важный инструмент предобработки текстов. В настоящей работе апробирован ряд способов решения задачи в рамках подхода «одностадийных предсказаний» (one-stage detectors). Полученный в работе результат сопоставим по качеству и более, чем в 3 раза превосходит по производительности современные методы выделения сочинительных связей.'},\n",
       "  'outputs': 'D',\n",
       "  'meta': {'abstract': 'Данная работа посвящена решению задачи выделения сочинительных связей в предложениях на английском языке нейросетевыми методами. Решение этой задачи позволяет устанавливать потенциально ценные связи и отношения между определёнными частями предложения; в том числе поэтому выделение сочинительных связей — важный инструмент предобработки текстов. В настоящей работе апробирован ряд способов решения задачи в рамках подхода «одностадийных предсказаний» (one-stage detectors). Полученный в работе результат сопоставим по качеству и более, чем в 3 раза превосходит по производительности современные методы выделения сочинительных связей.',\n",
       "   'id': '776'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Для решения задачи, поставленной в работе, применяются методы статистического моделирования и машинного обучения, которые позволяют выявить факторы, оказывающие наибольшее влияние на что?',\n",
       "   'option_a': 'На отток курьеров',\n",
       "   'option_b': 'На приток курьеров',\n",
       "   'option_c': 'На повышение вероятности оставления чаевых курьеру',\n",
       "   'option_d': 'На уменьшение зарплаты курьеров',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Удержание стабильного количества курьеров в компаниях, предоставляющих услуги доставки, является важным фактором для успешного функционирования на рынке. В данной дипломной работе рассматривается проблема ухода курьеров из компаний данного сегмента. Для ее решения применяются методы статистического моделирования и машинного обучения, которые позволяют выявить факторы, оказывающие наибольшее влияние на отток курьеров.'},\n",
       "  'outputs': 'A',\n",
       "  'meta': {'abstract': 'Удержание стабильного количества курьеров в компаниях, предоставляющих услуги доставки, является важным фактором для успешного функционирования на рынке. В данной дипломной работе рассматривается проблема ухода курьеров из компаний данного сегмента. Для ее решения применяются методы статистического моделирования и машинного обучения, которые позволяют выявить факторы, оказывающие наибольшее влияние на отток курьеров.',\n",
       "   'id': '777'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В работе показано, что при определённых условиях на матрицу переходных интенсивностей задача на полуоси может быть сведена к какой задаче?',\n",
       "   'option_a': 'К задаче на оси',\n",
       "   'option_b': 'К задаче на k-мерном кубе',\n",
       "   'option_c': 'К задаче на эллипсе',\n",
       "   'option_d': 'К задаче на шаре',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В настоящей работе рассматривается модель ветвящегося случайного блуждания на полуоси с одним источником ветвления положительной интенсивности и модель ветвящегося случайного блуждания на полуоси с периодически расположенными источниками ветвления одинаковой интенсивности. Объектом изучения является среднее число частиц в каждой точке.\\nПоказано, что при определённых условиях на матрицу переходных интенсивностей задача на полуоси может быть сведена к задачи на оси. Получено асимптотическое поведение средней численности частиц при t\\\\to\\\\infty в соответствующих моделях.'},\n",
       "  'outputs': 'A',\n",
       "  'meta': {'abstract': 'В настоящей работе рассматривается модель ветвящегося случайного блуждания на полуоси с одним источником ветвления положительной интенсивности и модель ветвящегося случайного блуждания на полуоси с периодически расположенными источниками ветвления одинаковой интенсивности. Объектом изучения является среднее число частиц в каждой точке.\\nПоказано, что при определённых условиях на матрицу переходных интенсивностей задача на полуоси может быть сведена к задачи на оси. Получено асимптотическое поведение средней численности частиц при t\\\\to\\\\infty в соответствующих моделях.',\n",
       "   'id': '778'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В работе исследуется асимптотическое поведение при t\\\\to\\\\infty чего?',\n",
       "   'option_a': 'Минимального числа частиц в каждой точке',\n",
       "   'option_b': 'Среднего числа частиц в каждой точке',\n",
       "   'option_c': 'Максимального числа частиц в каждой точке',\n",
       "   'option_d': 'Среднего числа частиц в точке 0',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В настоящей работе рассмотрена модель ветвящегося случайного блуждания (ВСБ) на полуоси с поглощением на границе. Исследуется асимптотическое поведение при t\\\\to\\\\infty среднего числа частиц в каждой точке. Показано, что данная задача может быть сведена к аналогичной задаче для ВСБ на полуоси с отражением на границе. Также в работе приведён алгоритм построения ВСБ на полуоси с поглощением на границе.'},\n",
       "  'outputs': 'B',\n",
       "  'meta': {'abstract': 'В настоящей работе рассмотрена модель ветвящегося случайного блуждания (ВСБ) на полуоси с поглощением на границе. Исследуется асимптотическое поведение при t\\\\to\\\\infty среднего числа частиц в каждой точке. Показано, что данная задача может быть сведена к аналогичной задаче для ВСБ на полуоси с отражением на границе. Также в работе приведён алгоритм построения ВСБ на полуоси с поглощением на границе.',\n",
       "   'id': '779'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В данной работе показано, что из нижних оценок на конедетерминированную сложность задач 0-1 permanent, Set cover и Hamiltonian cycle следуют нижние оценки на что?',\n",
       "   'option_a': 'На число паросочетаний в двудольном графе',\n",
       "   'option_b': 'На геометрические схемы для любого семейства многочленов',\n",
       "   'option_c': 'На асимптотику SAT решателя',\n",
       "   'option_d': 'На арифметические схемы для некоторого семейства многочленов константной степени',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В данной работе будет показано, что из нижних оценок на конедетерминированную сложность задач 0-1 permanent, Set cover и Hamiltonian cycle следуют нижние оценки на арифметические схемы для некоторого семейства многочленов константной степени. Также будет приведена верхняя оценка для задачи 0-1 permanent.'},\n",
       "  'outputs': 'D',\n",
       "  'meta': {'abstract': 'В данной работе будет показано, что из нижних оценок на конедетерминированную сложность задач 0-1 permanent, Set cover и Hamiltonian cycle следуют нижние оценки на арифметические схемы для некоторого семейства многочленов константной степени. Также будет приведена верхняя оценка для задачи 0-1 permanent.',\n",
       "   'id': '809'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В работе доказано, что упрощенная версия игры Merge War является какой задачей по теории сложности?',\n",
       "   'option_a': 'RP',\n",
       "   'option_b': 'P',\n",
       "   'option_c': 'NP-полной',\n",
       "   'option_d': 'ZPP',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Данная работа представляет исследование вычислительной задачи, основанной на компьютерной игре Merge War. Мы доказали, что упрощенная версия этой игры является NP-полной задачей, и предложили несколько способов ее решить в различных модификациях, включая экспоненциальные алгоритмы и полиномиальные алгоритмы с определенными ограничениями.'},\n",
       "  'outputs': 'C',\n",
       "  'meta': {'abstract': 'Данная работа представляет исследование вычислительной задачи, основанной на компьютерной игре Merge War. Мы доказали, что упрощенная версия этой игры является NP-полной задачей, и предложили несколько способов ее решить в различных модификациях, включая экспоненциальные алгоритмы и полиномиальные алгоритмы с определенными ограничениями.',\n",
       "   'id': '843'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В рамках данного диплома были получены новые возможности для разработки и реализации новых подсистем и алгоритмов для улучшения качества UnitTestBot, таких как',\n",
       "   'option_a': 'Модули графических тестов',\n",
       "   'option_b': 'Модули юнит тестов',\n",
       "   'option_c': 'Модули фаззинга и минимизации',\n",
       "   'option_d': 'Модули интеграционных тестов',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Данный диплом представляет собой разработку и внедрение виртуальной машины динамического символьного исполнения для языков программирования Java и Kotlin. Данная виртуальная машина основана на уже разработанном символьном движке и прототипе подсистемы конкретного исполнения UnitTestBot, инструмента для автоматической генерации тестов, и интегрирована в него для улучшения эффективности и надежности генерации тестов. Процесс разработки включал проведение обзора существующих инструментов, основанных на динамическом символьной исполнении, изучение структуры и кодовой базы инструмента UnitTestBot, разработку и реализацию архитектуры подсистемы конкретного исполнения на базе прототипа, а также ее интеграцию для создания виртуальной машины для динамического символьного исполнения. Целью было определить, может ли виртуальная машина улучшить генерацию тестов путем увеличения покрытия кода и сокращения числа некорректных и ненадежных тестов. Результаты реализации показывают, что реализованный подход значительно сокращает число неправильных тестов, не уменьшая покрытие кода. Более того, в рамках данного диплома были получены новые возможности для разработки и реализации новых подсистем и алгоритмов для улучшения качества UnitTestBot, таких как модули фаззинга и минимизации. А также представлены результаты участия UnitTestBot c реализованной подсистемой конкретного исполнения в соревновании SBFT 2023, где инструмент показал высокие результаты.'},\n",
       "  'outputs': 'C',\n",
       "  'meta': {'abstract': 'Данный диплом представляет собой разработку и внедрение виртуальной машины динамического символьного исполнения для языков программирования Java и Kotlin. Данная виртуальная машина основана на уже разработанном символьном движке и прототипе подсистемы конкретного исполнения UnitTestBot, инструмента для автоматической генерации тестов, и интегрирована в него для улучшения эффективности и надежности генерации тестов. Процесс разработки включал проведение обзора существующих инструментов, основанных на динамическом символьной исполнении, изучение структуры и кодовой базы инструмента UnitTestBot, разработку и реализацию архитектуры подсистемы конкретного исполнения на базе прототипа, а также ее интеграцию для создания виртуальной машины для динамического символьного исполнения. Целью было определить, может ли виртуальная машина улучшить генерацию тестов путем увеличения покрытия кода и сокращения числа некорректных и ненадежных тестов. Результаты реализации показывают, что реализованный подход значительно сокращает число неправильных тестов, не уменьшая покрытие кода. Более того, в рамках данного диплома были получены новые возможности для разработки и реализации новых подсистем и алгоритмов для улучшения качества UnitTestBot, таких как модули фаззинга и минимизации. А также представлены результаты участия UnitTestBot c реализованной подсистемой конкретного исполнения в соревновании SBFT 2023, где инструмент показал высокие результаты.',\n",
       "   'id': '849'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В какой задаче исследуются новые метрики в данной работе?',\n",
       "   'option_a': 'В задаче об идеалах',\n",
       "   'option_b': 'В задаче детекции объектов на видеокамере',\n",
       "   'option_c': 'В задаче нахождения НОД',\n",
       "   'option_d': 'В задаче генерации текста',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Исследуются новые метрики в задаче об идеалах (которая примыкает к знаменитой теореме Карлесона о короне).'},\n",
       "  'outputs': 'A',\n",
       "  'meta': {'abstract': 'Исследуются новые метрики в задаче об идеалах (которая примыкает к знаменитой теореме Карлесона о короне).',\n",
       "   'id': '903'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В данной работе рассматривается применение новейшего программного обеспечения для предсказывания чего?',\n",
       "   'option_a': 'Стабильности пептидов',\n",
       "   'option_b': 'Времени удерживания пептидов',\n",
       "   'option_c': 'Класса к которому принадлежат пептиды',\n",
       "   'option_d': 'Времени полураспада протонов',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В данной работе рассматривается применение новейшего программного обеспечения для предсказывания времени удерживания пептидов. Представлены результаты экспериментов на датасете HeLa и экспериментальном датасете, полученном в лаборатории. Предсказательные модели сравнены между собой при помощи графиков рассеивания и корелляции Пирсона в качестве метрики.'},\n",
       "  'outputs': 'B',\n",
       "  'meta': {'abstract': 'В данной работе рассматривается применение новейшего программного обеспечения для предсказывания времени удерживания пептидов. Представлены результаты экспериментов на датасете HeLa и экспериментальном датасете, полученном в лаборатории. Предсказательные модели сравнены между собой при помощи графиков рассеивания и корелляции Пирсона в качестве метрики.',\n",
       "   'id': '938'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В данной работе был выявлен метод нахождения отдельных групп песочной группы скошенного цилиндра и оценка чего?',\n",
       "   'option_a': 'Минимального числа песочных групп',\n",
       "   'option_b': 'Среднего числа частиц в точке 0',\n",
       "   'option_c': 'Количества вершин в скошенном цилиндре',\n",
       "   'option_d': 'Особенностей числа обвалов',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В данной работе был выявлен метод нахождения отдельных групп песочной группы скошенного цилиндра и оценка особенностей числа обвалов.'},\n",
       "  'outputs': 'D',\n",
       "  'meta': {'abstract': 'В данной работе был выявлен метод нахождения отдельных групп песочной группы скошенного цилиндра и оценка особенностей числа обвалов.',\n",
       "   'id': '951'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Реализованный инструмент основан на автоматической генерации тестов с помощью символьного исполнения, а также техники taint-анализа, и позволяет обнаруживать серьезные ошибки в анализируемой программе, например, разыменование нулевого указателя, запись или чтение вне границ массива, целочисленное деление на ноль или ',\n",
       "   'option_a': 'SQL-инъекция',\n",
       "   'option_b': 'Ошибка в отображении графического интерфейса приложения',\n",
       "   'option_c': 'Ошибка в архитектуре приложения',\n",
       "   'option_d': 'Ошибка в бизнес-логике приложения',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Данная выпускная квалификационная работа посвящена разработке статического анализатора кода для языка Java. Реализованный инструмент основан на автоматической генерации тестов с помощью символьного исполнения, а также техники taint-анализа, и позволяет обнаруживать серьезные ошибки в анализируемой программе, например, разыменование нулевого указателя, запись или чтение вне границ массива, целочисленное деление на ноль или SQL-инъекция.'},\n",
       "  'outputs': 'A',\n",
       "  'meta': {'abstract': 'Данная выпускная квалификационная работа посвящена разработке статического анализатора кода для языка Java. Реализованный инструмент основан на автоматической генерации тестов с помощью символьного исполнения, а также техники taint-анализа, и позволяет обнаруживать серьезные ошибки в анализируемой программе, например, разыменование нулевого указателя, запись или чтение вне границ массива, целочисленное деление на ноль или SQL-инъекция.',\n",
       "   'id': '953'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Какое покрытие имеют полученные на различных проектах результаты по сравнению с существующими аналогами?',\n",
       "   'option_a': 'Лучше',\n",
       "   'option_b': 'Невозможно сказать',\n",
       "   'option_c': 'Худше',\n",
       "   'option_d': 'Так же',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Модульное тестирование - важная задача, позволяющая находить ошибки в коде программ. Также модульные тесты позволяют проводить регрессионное тестирование. Автоматизация процесса написания модульных тестов позволит разработчикам сделать процесс написания тестов быстрее и надежнее. Данная работа представляет реализацию программной системы для автоматической генерации модульных тестов на языке Python. В работе рассматриваются существующие решения в данной области и представляется собственное решение, использующее методики вывода типов и фаззинга для генерации тестов. Полученные на различных проектах результаты имеют покрытие лучше, чем у существующих аналогов.'},\n",
       "  'outputs': 'A',\n",
       "  'meta': {'abstract': 'Модульное тестирование - важная задача, позволяющая находить ошибки в коде программ. Также модульные тесты позволяют проводить регрессионное тестирование. Автоматизация процесса написания модульных тестов позволит разработчикам сделать процесс написания тестов быстрее и надежнее. Данная работа представляет реализацию программной системы для автоматической генерации модульных тестов на языке Python. В работе рассматриваются существующие решения в данной области и представляется собственное решение, использующее методики вывода типов и фаззинга для генерации тестов. Полученные на различных проектах результаты имеют покрытие лучше, чем у существующих аналогов.',\n",
       "   'id': '975'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Во второй задаче работы была рассмотрена проблема автоматического подтверждения или отвержения гипотез о чем?',\n",
       "   'option_a': 'О том, что всякое односвязное компактное трёхмерное многообразие без края гомеоморфно трёхмерной сфере',\n",
       "   'option_b': 'О связи новых клиентов с контрагентами',\n",
       "   'option_c': 'О связи организаций с другими организациями в их бизнес кластере',\n",
       "   'option_d': 'О том, что граф связи об организациях планарен',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В данной работе рассмотрены задачи, связанные с обработкой большого графа знаний об организациях. В рамках первой задачи был разработан подход к обогащению сущностей атрибутами и связыванию информации о бизнесах из разных источников между собой. Для этого использовался подход компонент связности графа, которые обрабатывались независимо на разных узлах кластера. Во второй задаче была рассмотрена проблема автоматического подтверждения или отвержения гипотез о связи новых клиентов с контрагентами. Была поставлена задача бинарной классификации, рассмотрены различные модели и произведена оценка качества лучшей из них. В третьей задаче был рассмотрен вопрос выделения нетривиальных под-кластеров внутри компонент связности графа, для решения которого был использован метод вложения графов в многомерное векторное пространство, а также алгоритм кластеризации DBSCAN.'},\n",
       "  'outputs': 'B',\n",
       "  'meta': {'abstract': 'В данной работе рассмотрены задачи, связанные с обработкой большого графа знаний об организациях. В рамках первой задачи был разработан подход к обогащению сущностей атрибутами и связыванию информации о бизнесах из разных источников между собой. Для этого использовался подход компонент связности графа, которые обрабатывались независимо на разных узлах кластера. Во второй задаче была рассмотрена проблема автоматического подтверждения или отвержения гипотез о связи новых клиентов с контрагентами. Была поставлена задача бинарной классификации, рассмотрены различные модели и произведена оценка качества лучшей из них. В третьей задаче был рассмотрен вопрос выделения нетривиальных под-кластеров внутри компонент связности графа, для решения которого был использован метод вложения графов в многомерное векторное пространство, а также алгоритм кластеризации DBSCAN.',\n",
       "   'id': '989'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В какой метрике в работе доказывается непрерывность θ и ψ',\n",
       "   'option_a': 'В метрике Хаусдорфа',\n",
       "   'option_b': 'В метрике качества лидов',\n",
       "   'option_c': 'В метрике ROC-AUC',\n",
       "   'option_d': 'В метрике косинусного расстояния',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Рассмотрим выпуклую фигуру K на плоскости. Пусть А, В, С - три точки выбранные случайно и независимо на границе К. Обозначим через θ(К) среднее расстояние между А и В, а через ψ(K) - среднюю площадь треугольника АВС. В работе доказывается аналог изопериметрического неравенства для функционалов θ и ψ: среди фигур фиксированного  периметра наибольшее значение θ и ψ имеет круг . Также доказывается непрерывность θ и ψ в метрике Хаусдорфа.'},\n",
       "  'outputs': 'A',\n",
       "  'meta': {'abstract': 'Рассмотрим выпуклую фигуру K на плоскости. Пусть А, В, С - три точки выбранные случайно и независимо на границе К. Обозначим через θ(К) среднее расстояние между А и В, а через ψ(K) - среднюю площадь треугольника АВС. В работе доказывается аналог изопериметрического неравенства для функционалов θ и ψ: среди фигур фиксированного  периметра наибольшее значение θ и ψ имеет круг . Также доказывается непрерывность θ и ψ в метрике Хаусдорфа.',\n",
       "   'id': '1003'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Дипломная работа посвящена применению чего в высокочастотном трейдинге?',\n",
       "   'option_a': 'NP-полных алгоритмов',\n",
       "   'option_b': 'Более быстрой инфраструктуры',\n",
       "   'option_c': 'Глубокого обучения с подкреплением',\n",
       "   'option_d': 'Жадных алгоритмов',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'Дипломная работа посвящена применению глубокого обучения с подкреплением в высокочастотном трейдинге. Целью работы является создание практического применения глубокого обучения с подкреплением для оптимизации параметров торгового алгоритма. \\nРабота состоит из введения, 3 глав, заключения, списка использованной литературы. \\nВ первой главе описаны основные алгоритмы глубокого обучения с подкреплением и изучена возможность использования системы Ape-X.\\nВо второй главе подробно описаны улучшения среды и исследованы варианты архитектур.\\nВ третьей главе приведены результаты проведенных экспериментов и проведена оценка эффективности разработанного подхода.'},\n",
       "  'outputs': 'C',\n",
       "  'meta': {'abstract': 'Дипломная работа посвящена применению глубокого обучения с подкреплением в высокочастотном трейдинге. Целью работы является создание практического применения глубокого обучения с подкреплением для оптимизации параметров торгового алгоритма. \\nРабота состоит из введения, 3 глав, заключения, списка использованной литературы. \\nВ первой главе описаны основные алгоритмы глубокого обучения с подкреплением и изучена возможность использования системы Ape-X.\\nВо второй главе подробно описаны улучшения среды и исследованы варианты архитектур.\\nВ третьей главе приведены результаты проведенных экспериментов и проведена оценка эффективности разработанного подхода.',\n",
       "   'id': '1046'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В работе была предоставлена классификация коротких морфизмов по свойству абелевой периодичности их',\n",
       "   'option_a': 'Неподвижной точки',\n",
       "   'option_b': 'Подвижной точки',\n",
       "   'option_c': 'Системы линейных уравнений',\n",
       "   'option_d': 'Подгруппы в R^2',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В настоящей работе были рассмотрены две задачи о морфических словах:\\nоб их линдоновости и абелевой периодичности. Доказано, что в одном известом результате\\nсистема условий, составляющих критерий линдоновости морфического слова над бинарным алфавитом, является избыточной. Это дало новую формулировку критерия для бинарных слов, на основе ко-\\nторого сформирована гипотеза о критерии линдоновости морфических слов\\nнад алфавитами размера 3 и более. Кроме того, была предоставлена классификация коротких морфизмов по свой-\\nству абелевой периодичности их неподвижной точки. Приведены некоторые\\nнеобходимые и некоторые достаточные условия абелевой периодичности в\\nобщем случае, а также сформулирована гипотеза о необходимом и достаточном условии абелевой периодичности морфических слов.'},\n",
       "  'outputs': 'A',\n",
       "  'meta': {'abstract': 'В настоящей работе были рассмотрены две задачи о морфических словах:\\nоб их линдоновости и абелевой периодичности. Доказано, что в одном известом результате\\nсистема условий, составляющих критерий линдоновости морфического слова над бинарным алфавитом, является избыточной. Это дало новую формулировку критерия для бинарных слов, на основе ко-\\nторого сформирована гипотеза о критерии линдоновости морфических слов\\nнад алфавитами размера 3 и более. Кроме того, была предоставлена классификация коротких морфизмов по свой-\\nству абелевой периодичности их неподвижной точки. Приведены некоторые\\nнеобходимые и некоторые достаточные условия абелевой периодичности в\\nобщем случае, а также сформулирована гипотеза о необходимом и достаточном условии абелевой периодичности морфических слов.',\n",
       "   'id': '1062'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Что использует алгоритм, который рассматривается в первой части, где пики соответсвуют отношениям масс к зарядам?',\n",
       "   'option_a': 'Лесенки из как терминальных, так и внутренних ионов',\n",
       "   'option_b': 'Сырые масс-спектры',\n",
       "   'option_c': 'Обогащенные масс-спектры',\n",
       "   'option_d': 'CAH2_BOVIN',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В данной работе исследовались MS/MS спектры, снятые с белка CAH2_BOVIN. На протяжении работы предлагается некоторый набор алгоритмов, которые все лучше и лучше решают задачу нахождения и анализа лесенок, состоящих из внутренних фрагментных ионов.\\n\\nВ первой части рассматривается алгоритм, использующий сырые масс-спектры, где пики соответсвуют отношениям масс к зарядам.\\n\\nДалее данный подход переносится на масс-спектры, обработанные с помощью утилиты MS-Deconv, в которых пики соответствуют массам. Это позволяет улучшить качество аннотации фрагментных ионов.\\n\\nЗатем рассматривается финальный алгоритм, который решает проблемы предыдущих алгоритмов и позволяет с высокой точностью находить лесенки из как терминальных, так и внутренних ионов.\\n\\nВ конце работы анализируется распределение найденных лесенок из ионов и приводится несколько наблюдений о некоторых найденных особенностях.'},\n",
       "  'outputs': 'B',\n",
       "  'meta': {'abstract': 'В данной работе исследовались MS/MS спектры, снятые с белка CAH2_BOVIN. На протяжении работы предлагается некоторый набор алгоритмов, которые все лучше и лучше решают задачу нахождения и анализа лесенок, состоящих из внутренних фрагментных ионов.\\n\\nВ первой части рассматривается алгоритм, использующий сырые масс-спектры, где пики соответсвуют отношениям масс к зарядам.\\n\\nДалее данный подход переносится на масс-спектры, обработанные с помощью утилиты MS-Deconv, в которых пики соответствуют массам. Это позволяет улучшить качество аннотации фрагментных ионов.\\n\\nЗатем рассматривается финальный алгоритм, который решает проблемы предыдущих алгоритмов и позволяет с высокой точностью находить лесенки из как терминальных, так и внутренних ионов.\\n\\nВ конце работы анализируется распределение найденных лесенок из ионов и приводится несколько наблюдений о некоторых найденных особенностях.',\n",
       "   'id': '1064'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В работе удалось доказать, что количество f(n) триангуляций первого вида, состоящих из не более, чем n треугольников, растёт от n',\n",
       "   'option_a': 'Экспоненциально',\n",
       "   'option_b': 'Обратно пропорционально',\n",
       "   'option_c': 'Линейно',\n",
       "   'option_d': 'Квадратично',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': \"В выпускной работе описываются триангуляции вещественной проективной плоскости двух видов: у триангуляций первого вида ко всем вершинам, кроме трёх, примыкает по 6 треугольников, к двум вершинам примыкает по 5 треугольников, и одна вершина содержится ровно в 2 треугольниках; триангуляции второго вида содержат 4 особенные вершины, две из которых участвуют в 5 треугольниках каждая, к другим двум примыкает по 4 треугольника, и все остальные вершины триангуляции содержатся в 6 треугольниках каждая. Удалось доказать, что количество f(n) триангуляций первого вида, состоящих из не более, чем n треугольников, растёт квадратично от n: f(n) = Cn^2 + O(n^{3/2}), а также найдено значение константы C. Для количества триангуляций второго вида, состоящих из не более, чем n треугольников, g(n) были получены оценки снизу и сверху: для каких-то констант C и C' g(n) >= Cn^2 и g(n) <= C' n^2.\"},\n",
       "  'outputs': 'D',\n",
       "  'meta': {'abstract': \"В выпускной работе описываются триангуляции вещественной проективной плоскости двух видов: у триангуляций первого вида ко всем вершинам, кроме трёх, примыкает по 6 треугольников, к двум вершинам примыкает по 5 треугольников, и одна вершина содержится ровно в 2 треугольниках; триангуляции второго вида содержат 4 особенные вершины, две из которых участвуют в 5 треугольниках каждая, к другим двум примыкает по 4 треугольника, и все остальные вершины триангуляции содержатся в 6 треугольниках каждая. Удалось доказать, что количество f(n) триангуляций первого вида, состоящих из не более, чем n треугольников, растёт квадратично от n: f(n) = Cn^2 + O(n^{3/2}), а также найдено значение константы C. Для количества триангуляций второго вида, состоящих из не более, чем n треугольников, g(n) были получены оценки снизу и сверху: для каких-то констант C и C' g(n) >= Cn^2 и g(n) <= C' n^2.\",\n",
       "   'id': '1079'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'В основе алгоритма автоматической изоляции лежит автоматическая генерация символьных моделей для ',\n",
       "   'option_a': 'Внутренних функций',\n",
       "   'option_b': 'Классов',\n",
       "   'option_c': 'Лямбда функций',\n",
       "   'option_d': 'Внешних функций',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В рамках данной работы было разработано программное средство для автоматической изоляции тестируемого LLVM кода на базе символьной виртуальной машины KLEE. В основе алгоритма автоматической изоляции лежит автоматическая генерация символьных моделей для внешних функций. Полученный продукт был протестирован на промышленном проекте FRRouting. Тестирование показало, что реализованная функциональность значительно улучшает работу KLEE.'},\n",
       "  'outputs': 'D',\n",
       "  'meta': {'abstract': 'В рамках данной работы было разработано программное средство для автоматической изоляции тестируемого LLVM кода на базе символьной виртуальной машины KLEE. В основе алгоритма автоматической изоляции лежит автоматическая генерация символьных моделей для внешних функций. Полученный продукт был протестирован на промышленном проекте FRRouting. Тестирование показало, что реализованная функциональность значительно улучшает работу KLEE.',\n",
       "   'id': '1209'}},\n",
       " {'instruction': 'Задание содержит контексти и вопрос по теме {subject} и 4 варианта ответа A, B, C, D, из которых только один правильный.\\nКонтекст: {context}\\nВопрос: {text}\\nA {option_a}\\nB {option_b}\\nC {option_c}\\nD {option_d}\\nЗапишите букву правильного ответа\\nОтвет:',\n",
       "  'inputs': {'text': 'Данная работа раскрывает, как используя современные технологии, доступные в Андроид разработке и дизайне, создавать эффективный и понятный интерфейс, реализовывать и оптимизировать базу данных и, используя современные парадигмы программирования, реализовывать структуру коммуникации между чем и чем?',\n",
       "   'option_a': 'Микросервисами',\n",
       "   'option_b': 'Фронтенд модулем и бэкенд модулем',\n",
       "   'option_c': 'Пользователем и фронтенд модулем',\n",
       "   'option_d': 'Бэкенд модулем и базой данных',\n",
       "   'subject': 'Математика и компьютерные науки',\n",
       "   'context': 'В данной работе представлены реализация фронтенд части приложения по созданию игрового персонажа и часть реализации бэкенд части. Данная работа раскрывает, как используя современные технологии, доступные в Андроид разработке и дизайне, создавать эффективный и понятный интерфейс, реализовывать и оптимизировать базу данных и, используя современные парадигмы программирования, реализовывать структуру коммуникации между фронтенд модулем и бэкенд модулем.'},\n",
       "  'outputs': 'B',\n",
       "  'meta': {'abstract': 'В данной работе представлены реализация фронтенд части приложения по созданию игрового персонажа и часть реализации бэкенд части. Данная работа раскрывает, как используя современные технологии, доступные в Андроид разработке и дизайне, создавать эффективный и понятный интерфейс, реализовывать и оптимизировать базу данных и, используя современные парадигмы программирования, реализовывать структуру коммуникации между фронтенд модулем и бэкенд модулем.',\n",
       "   'id': '1238'}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(ARTIFACTS_DIR_PATH.joinpath(\"datasets/diplomas_asessors_questions/mcs_df_human_filled_processed.json\"), \"r\") as f:\n",
    "    asessors_dataset = json.load(f)[45:]\n",
    "asessors_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:59:18.407018Z",
     "iopub.status.busy": "2024-05-21T10:59:18.406133Z",
     "iopub.status.idle": "2024-05-21T10:59:18.428457Z",
     "shell.execute_reply": "2024-05-21T10:59:18.427711Z",
     "shell.execute_reply.started": "2024-05-21T10:59:18.406982Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(asessors_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-19T22:22:34.319135Z",
     "iopub.status.busy": "2024-05-19T22:22:34.318549Z",
     "iopub.status.idle": "2024-05-19T22:25:36.531039Z",
     "shell.execute_reply": "2024-05-19T22:25:36.530244Z",
     "shell.execute_reply.started": "2024-05-19T22:22:34.319108Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [02:05<00:00, 62.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n",
      "Loaded tokenizer\n"
     ]
    }
   ],
   "source": [
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    HUGGINGFACE_MODEL_TO_REPO[LLAMA_2_7B], \n",
    "    cache_dir=CACHE_DIR, \n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "print(\"Loaded model\")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    HUGGINGFACE_MODEL_TO_REPO[LLAMA_2_7B],\n",
    "    cache_dir=CACHE_DIR,\n",
    "    model_max_length=MODEL_MAX_LENGTH,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "print(\"Loaded tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T10:59:18.430366Z",
     "iopub.status.busy": "2024-05-21T10:59:18.429481Z",
     "iopub.status.idle": "2024-05-21T11:04:21.115279Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-21 10:59:25.694717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created config\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [03:40<00:00, 110.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Using pad_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import io\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import logging\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, Optional, Sequence\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "from llama_attn_replace_sft import replace_llama_attn\n",
    "from gptneox_attn_replace import replace_gpt_neox_attn\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from torch.distributed import barrier\n",
    "\n",
    "\n",
    "model_name = LLAMA_2_7B\n",
    "\n",
    "# replace_llama_attn(True, False, inference=True)\n",
    "\n",
    "# Set RoPE scaling factor\n",
    "config = transformers.AutoConfig.from_pretrained(\n",
    "    HUGGINGFACE_MODEL_TO_REPO[model_name],\n",
    "    cache_dir=CACHE_DIR,\n",
    ")\n",
    "\n",
    "orig_rope_scaling = getattr(config, \"rope_scaling\", None)\n",
    "if orig_rope_scaling is None:\n",
    "    orig_rope_scaling = {\"factor\": 1}\n",
    "orig_rope_scaling_factor = orig_rope_scaling[\"factor\"] if \"factor\" in orig_rope_scaling.keys() else 1\n",
    "orig_ctx_len = getattr(config, \"max_position_embeddings\", None)\n",
    "if orig_ctx_len:\n",
    "    orig_ctx_len *= orig_rope_scaling_factor\n",
    "    if MODEL_MAX_LENGTH > orig_ctx_len:\n",
    "        scaling_factor = float(math.ceil(MODEL_MAX_LENGTH / orig_ctx_len))\n",
    "        config.rope_scaling = {\"type\": \"linear\", \"factor\": scaling_factor}\n",
    "\n",
    "print(\"Created config\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(\n",
    "    HUGGINGFACE_MODEL_TO_REPO[model_name], \n",
    "    cache_dir=CACHE_DIR, \n",
    "    config=config,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "print(\"Loaded model\")\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
    "    HUGGINGFACE_MODEL_TO_REPO[model_name],\n",
    "    cache_dir=CACHE_DIR,\n",
    "    model_max_length=MODEL_MAX_LENGTH,\n",
    "    padding_side=\"right\",\n",
    "    use_fast=True,\n",
    ")\n",
    "\n",
    "print(\"Loaded tokenizer\")\n",
    "\n",
    "IGNORE_INDEX = -100\n",
    "DEFAULT_PAD_TOKEN = \"[PAD]\"\n",
    "DEFAULT_EOS_TOKEN = \"</s>\"\n",
    "DEFAULT_BOS_TOKEN = \"<s>\"\n",
    "DEFAULT_UNK_TOKEN = \"<unk>\"\n",
    "\n",
    "\n",
    "special_tokens_dict = dict()\n",
    "if tokenizer.pad_token is None:\n",
    "    special_tokens_dict[\"pad_token\"] = DEFAULT_PAD_TOKEN\n",
    "if tokenizer.eos_token is None:\n",
    "    special_tokens_dict[\"eos_token\"] = DEFAULT_EOS_TOKEN\n",
    "if tokenizer.bos_token is None:\n",
    "    special_tokens_dict[\"bos_token\"] = DEFAULT_BOS_TOKEN\n",
    "if tokenizer.unk_token is None:\n",
    "    special_tokens_dict[\"unk_token\"] = DEFAULT_UNK_TOKEN\n",
    "\n",
    "\n",
    "def smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict: Dict,\n",
    "    tokenizer: transformers.PreTrainedTokenizer,\n",
    "    model: transformers.PreTrainedModel,\n",
    "):\n",
    "    \"\"\"Resize tokenizer and embedding.\n",
    "\n",
    "    Note: This is the unoptimized version that may make your embedding size not be divisible by 64.\n",
    "    \"\"\"\n",
    "    num_new_tokens = tokenizer.add_special_tokens(special_tokens_dict)\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if num_new_tokens > 0:\n",
    "        input_embeddings = model.get_input_embeddings().weight.data\n",
    "        output_embeddings = model.get_output_embeddings().weight.data\n",
    "\n",
    "        input_embeddings_avg = input_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "        output_embeddings_avg = output_embeddings[:-num_new_tokens].mean(dim=0, keepdim=True)\n",
    "\n",
    "        input_embeddings[-num_new_tokens:] = input_embeddings_avg\n",
    "        output_embeddings[-num_new_tokens:] = output_embeddings_avg\n",
    "        \n",
    "smart_tokenizer_and_embedding_resize(\n",
    "    special_tokens_dict=special_tokens_dict,\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T11:04:21.119810Z",
     "iopub.status.busy": "2024-05-21T11:04:21.117742Z",
     "iopub.status.idle": "2024-05-21T11:04:58.553165Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading adapter_config.json: 100%|██████████| 674/674 [00:00<00:00, 2.81MB/s]\n",
      "Downloading adapter_model.bin: 100%|██████████| 1.08G/1.08G [00:19<00:00, 56.7MB/s]\n"
     ]
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "model_id = \"nvdenisov2002/llama-longLoRA-v1\"\n",
    "model = PeftModel.from_pretrained(model, model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluate model on inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-21T11:04:58.555622Z",
     "iopub.status.busy": "2024-05-21T11:04:58.554531Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06ede4640a30466e93e39422ad6ae849",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Rows...:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (25134 > 16384). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "from mera_helpers import construct_prompt\n",
    "from llm_helpers import calculate_token_interest_probs, get_answer\n",
    "\n",
    "for cur_input in inputs.columns:\n",
    "    if cur_input == \"id\":\n",
    "        continue\n",
    "    metric_dir_path = ARTIFACTS_DIR_PATH.joinpath(f\"metrics/diplomas_asessors_questions/{MODEL_EXPERIMENT_NAME}_{cur_input}_appended/{LLAMA_2_7B}/\")\n",
    "    metric_dir_path.mkdir(exist_ok=True, parents=True)\n",
    "    for i, row in tqdm(enumerate(asessors_dataset), total=len(asessors_dataset), desc=\"Rows...\"):\n",
    "        x = copy.deepcopy(row)\n",
    "        x['inputs']['context'] = inputs[cur_input].loc[int(x['meta']['id'])][:32000]\n",
    "        q = construct_prompt(x)\n",
    "        probs = calculate_token_interest_probs(q, tokenizer, model)\n",
    "        probs_entry = {\n",
    "            \"probs\": probs,\n",
    "            \"meta\": row[\"meta\"],\n",
    "        }\n",
    "        a = get_answer(probs)\n",
    "        a_entry = {\n",
    "            \"answer\": a,\n",
    "            \"meta\": row[\"meta\"],\n",
    "        }\n",
    "        with open(metric_dir_path.joinpath(\"probs_appended.jsons\"), \"a\") as f:\n",
    "            json.dump(probs_entry, f, ensure_ascii=False)\n",
    "            f.write(\"\\n\")\n",
    "        with open(metric_dir_path.joinpath(\"answers_appended.jsons\"), \"a\") as f:\n",
    "            json.dump(a_entry, f, ensure_ascii=False)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ARTIFACTS_DIR_PATH.joinpath(\"datasets/diplomas_asessors_questions/mcs_df_human_filled_processed.json\"), \"r\") as f:\n",
    "    asessors_dataset = json.load(f)\n",
    "asessors_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for cur_input in inputs.columns:\n",
    "    if cur_input == \"id\":\n",
    "        continue\n",
    "    metric_path = ARTIFACTS_DIR_PATH.joinpath(f\"metrics/diplomas_asessors_questions/{MODEL_EXPERIMENT_NAME}_{cur_input}_appended/{LLAMA_2_7B}/\")\n",
    "    some_path = metric_path.joinpath(\"answers_appended.jsons\")\n",
    "    with open(some_path, \"r\") as f:\n",
    "        answers = [json.loads(x) for x in f.readlines()]\n",
    "    pred = [x[\"answer\"] for x in answers]\n",
    "    true = [x[\"outputs\"] for x in asessors_dataset]\n",
    "    rows.append({\n",
    "        \"model\": MODEL_EXPERIMENT_NAME,\n",
    "        \"subset\": \"asessors_questions\",\n",
    "        \"split\": cur_input,\n",
    "        \"accuracy_score\": accuracy_score(true, pred),\n",
    "    })\n",
    "asessors_df = pd.DataFrame(rows)\n",
    "asessors_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Write results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "asessors_df.to_csv(METRICS_DIR_PATH.joinpath(f\"assessors_{MODEL_EXPERIMENT_NAME}_{'-'.join(INPUT_COLUMNS)}-run-2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
