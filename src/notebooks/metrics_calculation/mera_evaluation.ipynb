{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40ee45f-ee26-4b2a-b823-6df18d4ffb85",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9aaa92-a771-444f-870a-677a3abf27a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:55:16.501651Z",
     "iopub.status.busy": "2024-04-29T16:55:16.500931Z",
     "iopub.status.idle": "2024-04-29T16:55:36.401178Z",
     "shell.execute_reply": "2024-04-29T16:55:36.400479Z",
     "shell.execute_reply.started": "2024-04-29T16:55:16.501611Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "/home/jupyter/.local/lib/python3.10/site-packages/torch/cuda/__init__.py:619: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from definitions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1391a960-3b6a-498c-b660-de558ee836cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Auth to Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08b01ffb-4021-4869-ba2f-c957a872589d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:55:36.402854Z",
     "iopub.status.busy": "2024-04-29T16:55:36.402264Z",
     "iopub.status.idle": "2024-04-29T16:55:36.780974Z",
     "shell.execute_reply": "2024-04-29T16:55:36.780311Z",
     "shell.execute_reply.started": "2024-04-29T16:55:36.402822Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /tmp/xdg_cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5000298-97fd-46d0-a698-cea9f6c69922",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Ensuring CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2d0eccf-be2e-4d90-b638-626afaa04ba7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T14:02:26.444793Z",
     "iopub.status.busy": "2024-04-29T14:02:26.443781Z",
     "iopub.status.idle": "2024-04-29T14:02:26.585279Z",
     "shell.execute_reply": "2024-04-29T14:02:26.584087Z",
     "shell.execute_reply.started": "2024-04-29T14:02:26.444731Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Apr 29 14:02:26 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           On  | 00000000:8C:00.0 Off |                  Off |\n",
      "| N/A   29C    P0              26W / 250W |      4MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       881      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f49eee3-4ad6-4fa6-a9dc-6805dc419f72",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T14:02:26.587903Z",
     "iopub.status.busy": "2024-04-29T14:02:26.586807Z",
     "iopub.status.idle": "2024-04-29T14:02:26.710156Z",
     "shell.execute_reply": "2024-04-29T14:02:26.708919Z",
     "shell.execute_reply.started": "2024-04-29T14:02:26.587846Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "<torch.cuda.device object at 0x7f4c601ec820>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tesla V100-PCIE-32GB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())\n",
    "# True\n",
    "\n",
    "print(torch.cuda.device_count())\n",
    "# 1\n",
    "\n",
    "print(torch.cuda.current_device())\n",
    "# 0\n",
    "\n",
    "print(torch.cuda.device(0))\n",
    "# <torch.cuda.device at 0x7efce0b03be0>\n",
    "\n",
    "torch.cuda.get_device_name(0)\n",
    "# 'GeForce GTX 950M'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dcb00b-2711-4cb3-b632-c7ffc8123dde",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Try to run MERA lm-eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298cbeae-a46f-41fa-9efe-44db59ffc558",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T14:03:16.578525Z",
     "iopub.status.busy": "2024-04-29T14:03:16.577490Z",
     "iopub.status.idle": "2024-04-29T16:11:00.691635Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Tasks: ['rummlu']\n",
      "Using `model.prepare_inputs_for_generation` method for `model.forward`.\n",
      "Searching for good max length. OOM at length 11500\n",
      "length 5800 not failed but it can be lengthier\n",
      "length 8650 not failed but it can be lengthier\n",
      "Searching for good max length. OOM at length 10075\n",
      "length 9362 not failed but it can be lengthier\n",
      "Searching for good max length. OOM at length 9718\n",
      "length 9539 not failed but it can be lengthier\n",
      "Searching for good max length. OOM at length 9628\n",
      "Searching for good max length. OOM at length 9583\n",
      "9560 is good enough\n",
      "Task: rummlu; number of docs: 961\n",
      "Running loglikelihood requests\n",
      "{\n",
      "  \"results\": {\n",
      "    \"rummlu\": {\n",
      "      \"metric\": 0.0,\n",
      "      \"metric_stderr\": 0.0\n",
      "    }\n",
      "  },\n",
      "  \"versions\": {\n",
      "    \"rummlu\": 0\n",
      "  },\n",
      "  \"tasks\": {\n",
      "    \"rummlu\": 961\n",
      "  },\n",
      "  \"config\": {\n",
      "    \"model\": \"hf-causal-experimental\",\n",
      "    \"model_args\": \"pretrained=mistralai/Mistral-7B-v0.1,dtype=auto,max_length=11500\",\n",
      "    \"num_fewshot\": 5,\n",
      "    \"batch_size\": \"1\",\n",
      "    \"batch_sizes\": [],\n",
      "    \"device\": \"cuda\",\n",
      "    \"no_cache\": true,\n",
      "    \"limit\": null,\n",
      "    \"bootstrap_iters\": 100000,\n",
      "    \"description_dict\": {},\n",
      "    \"pretty_env_info\": \"PyTorch version: 2.3.0+cu121\\nIs debug build: False\\nCUDA used to build PyTorch: 12.1\\nROCM used to build PyTorch: N/A\\n\\nOS: Ubuntu 22.04.2 LTS (x86_64)\\nGCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\\nClang version: Could not collect\\nCMake version: version 3.25.2\\nLibc version: glibc-2.35\\n\\nPython version: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] (64-bit runtime)\\nPython platform: Linux-5.13.0-40-generic-x86_64-with-glibc2.35\\nIs CUDA available: True\\nCUDA runtime version: 11.8.89\\nCUDA_MODULE_LOADING set to: LAZY\\nGPU models and configuration: GPU 0: Tesla V100-PCIE-32GB\\nNvidia driver version: 535.161.08\\ncuDNN version: Probably one of the following:\\n/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0\\n/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0\\n/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0\\n/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0\\n/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0\\n/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0\\n/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0\\nHIP runtime version: N/A\\nMIOpen runtime version: N/A\\nIs XNNPACK available: True\\n\\nCPU:\\nArchitecture:                    x86_64\\nCPU op-mode(s):                  32-bit, 64-bit\\nAddress sizes:                   40 bits physical, 48 bits virtual\\nByte Order:                      Little Endian\\nCPU(s):                          8\\nOn-line CPU(s) list:             0-7\\nVendor ID:                       GenuineIntel\\nModel name:                      Intel Core Processor (Broadwell, no TSX)\\nCPU family:                      6\\nModel:                           61\\nThread(s) per core:              2\\nCore(s) per socket:              4\\nSocket(s):                       1\\nStepping:                        2\\nBogoMIPS:                        3999.99\\nFlags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap xsaveopt arat md_clear\\nHypervisor vendor:               KVM\\nVirtualization type:             full\\nL1d cache:                       256 KiB (8 instances)\\nL1i cache:                       256 KiB (8 instances)\\nL2 cache:                        16 MiB (4 instances)\\nL3 cache:                        16 MiB (1 instance)\\nNUMA node(s):                    1\\nNUMA node0 CPU(s):               0-7\\nVulnerability Itlb multihit:     KVM: Mitigation: VMX unsupported\\nVulnerability L1tf:              Mitigation; PTE Inversion\\nVulnerability Mds:               Mitigation; Clear CPU buffers; SMT Host state unknown\\nVulnerability Meltdown:          Mitigation; PTI\\nVulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp\\nVulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\\nVulnerability Spectre v2:        Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling\\nVulnerability Srbds:             Unknown: Dependent on hypervisor status\\nVulnerability Tsx async abort:   Not affected\\n\\nVersions of relevant libraries:\\n[pip3] numpy==1.25.1\\n[pip3] torch==2.3.0\\n[pip3] torchaudio==2.0.2+cu118\\n[pip3] torchdata==0.6.1\\n[pip3] torchsummary==1.5.1\\n[pip3] torchtext==0.15.2\\n[pip3] torchvision==0.15.2+cu118\\n[pip3] triton==2.3.0\\n[conda] Could not collect\",\n",
      "    \"transformers_version\": \"Transformers: 4.39.3\",\n",
      "    \"current_dir_commit\": \"\",\n",
      "    \"upper_dir_commit\": \"\"\n",
      "  }\n",
      "}\n",
      "hf-causal-experimental (pretrained=mistralai/Mistral-7B-v0.1,dtype=auto,max_length=11500), limit: None, num_fewshot: 5, batch_size: 1\n",
      "CPU times: user 1min 3s, sys: 1min 34s, total: 2min 38s\n",
      "Wall time: 2h 7min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-04-29 14:03:34.148799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Downloading shards: 100%|██████████| 2/2 [00:00<00:00, 593.67it/s]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [07:49<00:00, 234.82s/it]\n",
      "Downloading readme: 100%|██████████| 137k/137k [00:00<00:00, 656kB/s] \n",
      "Downloading data: 100%|██████████| 13.3M/13.3M [00:00<00:00, 13.7MB/s]\n",
      "Downloading data: 100%|██████████| 845k/845k [00:00<00:00, 1.93MB/s]\n",
      "Generating public_test split: 100%|██████████| 10033/10033 [00:00<00:00, 38706.73 examples/s]\n",
      "Generating test split: 100%|██████████| 961/961 [00:00<00:00, 69785.25 examples/s]\n",
      "100%|██████████| 3844/3844 [1:50:52<00:00,  1.73s/it]  \n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! CUDA_VISIBLE_DEVICES=0 python3 /home/jupyter/work/resources/MERA/lm-evaluation-harness/main.py --model hf-causal-experimental --model_args pretrained=mistralai/Mistral-7B-v0.1,dtype=auto,max_length=11500 \\\n",
    "--device cuda --output_base_path=\"$PWD/mera_results/Mistral-7B-v0.1_defaults\" --batch_size=1 \\\n",
    "--inference --write_out --no_cache --tasks rummlu --num_fewshot=5 \\\n",
    "--output_path=\"$PWD/mera_results/Mistral-7B-v0.1_defaults/rummlu_result.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9fd462-b878-49df-9188-c829f06c7663",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### View MERA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b177c0-cf1f-4d84-b2f9-429453151785",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:16:42.234990Z",
     "iopub.status.busy": "2024-04-29T16:16:42.234045Z",
     "iopub.status.idle": "2024-04-29T16:16:42.270810Z",
     "shell.execute_reply": "2024-04-29T16:16:42.269537Z",
     "shell.execute_reply.started": "2024-04-29T16:16:42.234953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/work/resources/long_context_LLMs/notebooks/metrics_calculation\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b6298dd-44eb-4ac0-ab08-d19a1809996a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:16:43.805936Z",
     "iopub.status.busy": "2024-04-29T16:16:43.804820Z",
     "iopub.status.idle": "2024-04-29T16:16:43.830268Z",
     "shell.execute_reply": "2024-04-29T16:16:43.828939Z",
     "shell.execute_reply.started": "2024-04-29T16:16:43.805886Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__pycache__\n",
      "knowledge_tests_evaluator.ipynb\n",
      "llm_helpers.py\n",
      "mera_evaluation.ipynb\n",
      "mera_results\n",
      "mmlu_ru_evaluator.ipynb\n",
      "open_book_qa_evaluator.ipynb\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e805b3fc-be07-4b28-9a02-4cab71ff1d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:20:52.946847Z",
     "iopub.status.busy": "2024-04-29T16:20:52.946134Z",
     "iopub.status.idle": "2024-04-29T16:20:52.962797Z",
     "shell.execute_reply": "2024-04-29T16:20:52.961776Z",
     "shell.execute_reply.started": "2024-04-29T16:20:52.946796Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./mera_results/Mistral-7B-v0.1_defaults/rummlu_result.json\", \"r\") as f:\n",
    "    rummlu_result = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76fd8887-68ea-4f2f-88a2-2034dbb842a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:21:27.006745Z",
     "iopub.status.busy": "2024-04-29T16:21:27.005985Z",
     "iopub.status.idle": "2024-04-29T16:21:27.030966Z",
     "shell.execute_reply": "2024-04-29T16:21:27.029752Z",
     "shell.execute_reply.started": "2024-04-29T16:21:27.006666Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0+cu121\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 12.1\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 22.04.2 LTS (x86_64)\n",
      "GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.25.2\n",
      "Libc version: glibc-2.35\n",
      "\n",
      "Python version: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] (64-bit runtime)\n",
      "Python platform: Linux-5.13.0-40-generic-x86_64-with-glibc2.35\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 11.8.89\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: GPU 0: Tesla V100-PCIE-32GB\n",
      "Nvidia driver version: 535.161.08\n",
      "cuDNN version: Probably one of the following:\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "CPU:\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Address sizes:                   40 bits physical, 48 bits virtual\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          8\n",
      "On-line CPU(s) list:             0-7\n",
      "Vendor ID:                       GenuineIntel\n",
      "Model name:                      Intel Core Processor (Broadwell, no TSX)\n",
      "CPU family:                      6\n",
      "Model:                           61\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              4\n",
      "Socket(s):                       1\n",
      "Stepping:                        2\n",
      "BogoMIPS:                        3999.99\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap xsaveopt arat md_clear\n",
      "Hypervisor vendor:               KVM\n",
      "Virtualization type:             full\n",
      "L1d cache:                       256 KiB (8 instances)\n",
      "L1i cache:                       256 KiB (8 instances)\n",
      "L2 cache:                        16 MiB (4 instances)\n",
      "L3 cache:                        16 MiB (1 instance)\n",
      "NUMA node(s):                    1\n",
      "NUMA node0 CPU(s):               0-7\n",
      "Vulnerability Itlb multihit:     KVM: Mitigation: VMX unsupported\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
      "Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT Host state unknown\n",
      "Vulnerability Meltdown:          Mitigation; PTI\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling\n",
      "Vulnerability Srbds:             Unknown: Dependent on hypervisor status\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.25.1\n",
      "[pip3] torch==2.3.0\n",
      "[pip3] torchaudio==2.0.2+cu118\n",
      "[pip3] torchdata==0.6.1\n",
      "[pip3] torchsummary==1.5.1\n",
      "[pip3] torchtext==0.15.2\n",
      "[pip3] torchvision==0.15.2+cu118\n",
      "[pip3] triton==2.3.0\n",
      "[conda] Could not collect\n"
     ]
    }
   ],
   "source": [
    "print(rummlu_result['config']['pretty_env_info'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "387f304a-8a04-4bf5-9f58-c83d60757817",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:24:27.012979Z",
     "iopub.status.busy": "2024-04-29T16:24:27.012291Z",
     "iopub.status.idle": "2024-04-29T16:24:27.037369Z",
     "shell.execute_reply": "2024-04-29T16:24:27.036261Z",
     "shell.execute_reply.started": "2024-04-29T16:24:27.012929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0+cu121\n",
      "Is debug build: False\n",
      "CUDA used to build PyTorch: 12.1\n",
      "ROCM used to build PyTorch: N/A\n",
      "\n",
      "OS: Ubuntu 22.04.2 LTS (x86_64)\n",
      "GCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "Clang version: Could not collect\n",
      "CMake version: version 3.25.2\n",
      "Libc version: glibc-2.35\n",
      "\n",
      "Python version: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] (64-bit runtime)\n",
      "Python platform: Linux-5.13.0-40-generic-x86_64-with-glibc2.35\n",
      "Is CUDA available: True\n",
      "CUDA runtime version: 11.8.89\n",
      "CUDA_MODULE_LOADING set to: LAZY\n",
      "GPU models and configuration: GPU 0: Tesla V100-PCIE-32GB\n",
      "Nvidia driver version: 535.161.08\n",
      "cuDNN version: Probably one of the following:\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0\n",
      "/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0\n",
      "HIP runtime version: N/A\n",
      "MIOpen runtime version: N/A\n",
      "Is XNNPACK available: True\n",
      "\n",
      "CPU:\n",
      "Architecture:                    x86_64\n",
      "CPU op-mode(s):                  32-bit, 64-bit\n",
      "Address sizes:                   40 bits physical, 48 bits virtual\n",
      "Byte Order:                      Little Endian\n",
      "CPU(s):                          8\n",
      "On-line CPU(s) list:             0-7\n",
      "Vendor ID:                       GenuineIntel\n",
      "Model name:                      Intel Core Processor (Broadwell, no TSX)\n",
      "CPU family:                      6\n",
      "Model:                           61\n",
      "Thread(s) per core:              2\n",
      "Core(s) per socket:              4\n",
      "Socket(s):                       1\n",
      "Stepping:                        2\n",
      "BogoMIPS:                        3999.99\n",
      "Flags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap xsaveopt arat md_clear\n",
      "Hypervisor vendor:               KVM\n",
      "Virtualization type:             full\n",
      "L1d cache:                       256 KiB (8 instances)\n",
      "L1i cache:                       256 KiB (8 instances)\n",
      "L2 cache:                        16 MiB (4 instances)\n",
      "L3 cache:                        16 MiB (1 instance)\n",
      "NUMA node(s):                    1\n",
      "NUMA node0 CPU(s):               0-7\n",
      "Vulnerability Itlb multihit:     KVM: Mitigation: VMX unsupported\n",
      "Vulnerability L1tf:              Mitigation; PTE Inversion\n",
      "Vulnerability Mds:               Mitigation; Clear CPU buffers; SMT Host state unknown\n",
      "Vulnerability Meltdown:          Mitigation; PTI\n",
      "Vulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp\n",
      "Vulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\n",
      "Vulnerability Spectre v2:        Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling\n",
      "Vulnerability Srbds:             Unknown: Dependent on hypervisor status\n",
      "Vulnerability Tsx async abort:   Not affected\n",
      "\n",
      "Versions of relevant libraries:\n",
      "[pip3] numpy==1.25.1\n",
      "[pip3] torch==2.3.0\n",
      "[pip3] torchaudio==2.0.2+cu118\n",
      "[pip3] torchdata==0.6.1\n",
      "[pip3] torchsummary==1.5.1\n",
      "[pip3] torchtext==0.15.2\n",
      "[pip3] torchvision==0.15.2+cu118\n",
      "[pip3] triton==2.3.0\n",
      "[conda] Could not collect\n"
     ]
    }
   ],
   "source": [
    "with open(\"./mera_results/Mistral-7B-v0.1_defaults/evaluation_config.json\", \"r\") as f:\n",
    "    evaluation_config = json.load(f)\n",
    "print(evaluation_config['pretty_env_info'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bb94ec-4784-4749-806e-5c42c3c0e539",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Download ru_mmlu from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9ec775c-b4f8-4ae2-af1c-a0814bd54838",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T17:07:23.814886Z",
     "iopub.status.busy": "2024-04-29T17:07:23.814161Z",
     "iopub.status.idle": "2024-04-29T17:07:24.404184Z",
     "shell.execute_reply": "2024-04-29T17:07:24.403605Z",
     "shell.execute_reply.started": "2024-04-29T17:07:23.814844Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100    59  100    59    0     0    103      0 --:--:-- --:--:-- --:--:--   103\n"
     ]
    }
   ],
   "source": [
    "! curl -X GET \\\n",
    "     \"https://datasets-server.huggingface.co/rows?dataset=ai-forever%2FMERA&config=bps&split=test&length=1000\" >ru_mmlu_dataset_test.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c892835e-4ba4-44e2-af76-fc17e3dc5230",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T17:07:26.435511Z",
     "iopub.status.busy": "2024-04-29T17:07:26.434834Z",
     "iopub.status.idle": "2024-04-29T17:07:26.444897Z",
     "shell.execute_reply": "2024-04-29T17:07:26.444336Z",
     "shell.execute_reply.started": "2024-04-29T17:07:26.435465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./ru_mmlu_dataset_test.json\", \"r\") as f:\n",
    "    ru_mmlu_dataset_test = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd039089-f1ce-4355-aa78-6467acd5d528",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T17:07:27.310767Z",
     "iopub.status.busy": "2024-04-29T17:07:27.310136Z",
     "iopub.status.idle": "2024-04-29T17:07:27.326221Z",
     "shell.execute_reply": "2024-04-29T17:07:27.325668Z",
     "shell.execute_reply.started": "2024-04-29T17:07:27.310731Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['error'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_mmlu_dataset_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "280896df-e64b-44b1-9f2c-23a66aedb713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T17:07:44.708384Z",
     "iopub.status.busy": "2024-04-29T17:07:44.707737Z",
     "iopub.status.idle": "2024-04-29T17:07:44.718416Z",
     "shell.execute_reply": "2024-04-29T17:07:44.717861Z",
     "shell.execute_reply.started": "2024-04-29T17:07:44.708347Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Parameter 'length' must not be greater than 100\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_mmlu_dataset_test['error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3b3fb5b-4d4b-4210-988a-ba9f942f0f19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T17:07:27.730757Z",
     "iopub.status.busy": "2024-04-29T17:07:27.730054Z",
     "iopub.status.idle": "2024-04-29T17:07:27.747656Z",
     "shell.execute_reply": "2024-04-29T17:07:27.746794Z",
     "shell.execute_reply.started": "2024-04-29T17:07:27.730715Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'num_rows_per_page'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-556ad611e31a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mru_mmlu_dataset_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_rows_per_page'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'num_rows_per_page'"
     ]
    }
   ],
   "source": [
    "ru_mmlu_dataset_test['num_rows_per_page']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11a7083b-749c-40a9-ac96-ade92e8b466c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T17:06:51.995067Z",
     "iopub.status.busy": "2024-04-29T17:06:51.994294Z",
     "iopub.status.idle": "2024-04-29T17:06:52.006158Z",
     "shell.execute_reply": "2024-04-29T17:06:52.005613Z",
     "shell.execute_reply.started": "2024-04-29T17:06:51.995024Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_mmlu_dataset_test['rows'].__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "201da8fd-bede-4dfd-a34b-d16f6f2f9bff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T17:06:53.956856Z",
     "iopub.status.busy": "2024-04-29T17:06:53.956183Z",
     "iopub.status.idle": "2024-04-29T17:06:53.966189Z",
     "shell.execute_reply": "2024-04-29T17:06:53.965641Z",
     "shell.execute_reply.started": "2024-04-29T17:06:53.956823Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature_idx': 0,\n",
       "  'name': 'instruction',\n",
       "  'type': {'dtype': 'string', '_type': 'Value'}},\n",
       " {'feature_idx': 1,\n",
       "  'name': 'inputs',\n",
       "  'type': {'dtype': 'string', '_type': 'Value'}},\n",
       " {'feature_idx': 2,\n",
       "  'name': 'outputs',\n",
       "  'type': {'dtype': 'string', '_type': 'Value'}},\n",
       " {'feature_idx': 3,\n",
       "  'name': 'meta',\n",
       "  'type': {'id': {'dtype': 'int32', '_type': 'Value'}}}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ru_mmlu_dataset_test['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d8363a48-3b19-415c-8077-1134236e77d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T17:15:33.874755Z",
     "iopub.status.busy": "2024-04-29T17:15:33.874043Z",
     "iopub.status.idle": "2024-04-29T17:15:39.166102Z",
     "shell.execute_reply": "2024-04-29T17:15:39.165389Z",
     "shell.execute_reply.started": "2024-04-29T17:15:33.874717Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ai-forever/MERA\", \"rummlu\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fe11081-ebbc-4eb9-9c56-62af803984c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T17:16:35.130621Z",
     "iopub.status.busy": "2024-04-29T17:16:35.129961Z",
     "iopub.status.idle": "2024-04-29T17:16:35.142414Z",
     "shell.execute_reply": "2024-04-29T17:16:35.141794Z",
     "shell.execute_reply.started": "2024-04-29T17:16:35.130582Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    print(x['outputs'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27cc4a3-3227-4a1d-969b-6307829f7ef4",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate how many correct answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffbfb09-0427-4646-8e17-4ec967069ceb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:56:49.347303Z",
     "iopub.status.busy": "2024-04-29T16:56:49.346490Z",
     "iopub.status.idle": "2024-04-29T16:56:49.359782Z",
     "shell.execute_reply": "2024-04-29T16:56:49.359243Z",
     "shell.execute_reply.started": "2024-04-29T16:56:49.347262Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open(\"./mera_results/Mistral-7B-v0.1_defaults/lm_harness_logs_rummlu/input_docs.json\", \"r\") as f:\n",
    "    # input_docs = json.load(f)\n",
    "with open(\"./mera_results/Mistral-7B-v0.1_defaults/lm_harness_logs_rummlu/output_answers.json\", \"r\") as f:\n",
    "    output_answers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dac2f5b-0601-4719-82f0-429bff716020",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:57:29.480357Z",
     "iopub.status.busy": "2024-04-29T16:57:29.479637Z",
     "iopub.status.idle": "2024-04-29T16:57:29.489629Z",
     "shell.execute_reply": "2024-04-29T16:57:29.488749Z",
     "shell.execute_reply.started": "2024-04-29T16:57:29.480313Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 [0, -837.1574096679688]\n"
     ]
    }
   ],
   "source": [
    "for output_answer_key, output_answer_value, in output_answers.items():\n",
    "    print(output_answer_key, output_answer_value[0])\n",
    "    # print(output_answers.keys())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a8e3ba-ec2b-450d-a816-989c533f8d91",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Try to convert results to submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b68329e7-98e3-402a-9f39-6bbca6d07c67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-29T16:46:49.720615Z",
     "iopub.status.busy": "2024-04-29T16:46:49.719695Z",
     "iopub.status.idle": "2024-04-29T16:46:58.605954Z",
     "shell.execute_reply": "2024-04-29T16:46:58.604275Z",
     "shell.execute_reply.started": "2024-04-29T16:46:49.720578Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/jupyter/work/resources/MERA/lm-evaluation-harness/scripts/log_to_submission.py\", line 383, in <module>\n",
      "    main()\n",
      "  File \"/home/jupyter/work/resources/MERA/lm-evaluation-harness/scripts/log_to_submission.py\", line 376, in main\n",
      "    _ = create_submission(args.outputs_dir, args.dst_dir)\n",
      "  File \"/home/jupyter/work/resources/MERA/lm-evaluation-harness/scripts/log_to_submission.py\", line 351, in create_submission\n",
      "    _ = task.convert()\n",
      "  File \"/home/jupyter/work/resources/MERA/lm-evaluation-harness/scripts/log_to_submission.py\", line 82, in convert\n",
      "    submission = self.outputs_to_submission(load_json(self.outputs_path))\n",
      "  File \"/home/jupyter/work/resources/MERA/lm-evaluation-harness/scripts/log_to_submission.py\", line 28, in load_json\n",
      "    with open(path, \"r\", encoding=\"utf-8\") as file:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './lm_harness_logs_bps/output_answers.json'\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Process exited with code 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-121739a287e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' python3 /home/jupyter/work/resources/MERA/lm-evaluation-harness/scripts/log_to_submission.py --outputs_dir .'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/ml_kernel/kernel.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(code)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_script_executor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mScriptExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_output_error_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_script_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_message_handlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/kernel/lib/python3.10/site-packages/ml_kernel/script_executor.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, lang, code)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mreturn_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Process exited with code %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mreturn_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mException\u001b[0m: Process exited with code 1"
     ]
    }
   ],
   "source": [
    "! python3 /home/jupyter/work/resources/MERA/lm-evaluation-harness/scripts/log_to_submission.py --outputs_dir ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10deea4f-1edc-42e3-9a53-fcfafd528db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
