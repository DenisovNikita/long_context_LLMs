{
  "results": {
    "rummlu": {
      "metric": 0.0,
      "metric_stderr": 0.0
    }
  },
  "versions": {
    "rummlu": 0
  },
  "tasks": {
    "rummlu": 961
  },
  "config": {
    "model": "hf-causal-experimental",
    "model_args": "pretrained=mistralai/Mistral-7B-v0.1,dtype=auto,max_length=11500",
    "num_fewshot": 5,
    "batch_size": "1",
    "batch_sizes": [],
    "device": "cuda",
    "no_cache": true,
    "limit": null,
    "bootstrap_iters": 100000,
    "description_dict": {},
    "pretty_env_info": "PyTorch version: 2.3.0+cu121\nIs debug build: False\nCUDA used to build PyTorch: 12.1\nROCM used to build PyTorch: N/A\n\nOS: Ubuntu 22.04.2 LTS (x86_64)\nGCC version: (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\nClang version: Could not collect\nCMake version: version 3.25.2\nLibc version: glibc-2.35\n\nPython version: 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0] (64-bit runtime)\nPython platform: Linux-5.13.0-40-generic-x86_64-with-glibc2.35\nIs CUDA available: True\nCUDA runtime version: 11.8.89\nCUDA_MODULE_LOADING set to: LAZY\nGPU models and configuration: GPU 0: Tesla V100-PCIE-32GB\nNvidia driver version: 535.161.08\ncuDNN version: Probably one of the following:\n/usr/lib/x86_64-linux-gnu/libcudnn.so.8.9.0\n/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.9.0\n/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.9.0\n/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.9.0\n/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.9.0\n/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.9.0\n/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.9.0\nHIP runtime version: N/A\nMIOpen runtime version: N/A\nIs XNNPACK available: True\n\nCPU:\nArchitecture:                    x86_64\nCPU op-mode(s):                  32-bit, 64-bit\nAddress sizes:                   40 bits physical, 48 bits virtual\nByte Order:                      Little Endian\nCPU(s):                          8\nOn-line CPU(s) list:             0-7\nVendor ID:                       GenuineIntel\nModel name:                      Intel Core Processor (Broadwell, no TSX)\nCPU family:                      6\nModel:                           61\nThread(s) per core:              2\nCore(s) per socket:              4\nSocket(s):                       1\nStepping:                        2\nBogoMIPS:                        3999.99\nFlags:                           fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase bmi1 avx2 smep bmi2 erms invpcid rdseed adx smap xsaveopt arat md_clear\nHypervisor vendor:               KVM\nVirtualization type:             full\nL1d cache:                       256 KiB (8 instances)\nL1i cache:                       256 KiB (8 instances)\nL2 cache:                        16 MiB (4 instances)\nL3 cache:                        16 MiB (1 instance)\nNUMA node(s):                    1\nNUMA node0 CPU(s):               0-7\nVulnerability Itlb multihit:     KVM: Mitigation: VMX unsupported\nVulnerability L1tf:              Mitigation; PTE Inversion\nVulnerability Mds:               Mitigation; Clear CPU buffers; SMT Host state unknown\nVulnerability Meltdown:          Mitigation; PTI\nVulnerability Spec store bypass: Mitigation; Speculative Store Bypass disabled via prctl and seccomp\nVulnerability Spectre v1:        Mitigation; usercopy/swapgs barriers and __user pointer sanitization\nVulnerability Spectre v2:        Mitigation; Retpolines, IBPB conditional, IBRS_FW, STIBP conditional, RSB filling\nVulnerability Srbds:             Unknown: Dependent on hypervisor status\nVulnerability Tsx async abort:   Not affected\n\nVersions of relevant libraries:\n[pip3] numpy==1.25.1\n[pip3] torch==2.3.0\n[pip3] torchaudio==2.0.2+cu118\n[pip3] torchdata==0.6.1\n[pip3] torchsummary==1.5.1\n[pip3] torchtext==0.15.2\n[pip3] torchvision==0.15.2+cu118\n[pip3] triton==2.3.0\n[conda] Could not collect",
    "transformers_version": "Transformers: 4.39.3",
    "current_dir_commit": "",
    "upper_dir_commit": ""
  }
}